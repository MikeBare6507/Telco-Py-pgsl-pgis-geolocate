import pandas as pd
import numpy as np
import geopandas as gpd
from shapely.wkt import loads as wkt_loads
from sqlalchemy import create_engine, text
from sklearn.cluster import DBSCAN
from sklearn.cluster import KMeans
import os
import random
from shapely.ops import nearest_points
import warnings

# Suppress specific warnings from scikit-learn
warnings.filterwarnings("ignore", category=UserWarning, module='sklearn.cluster._kmeans')

# Create SQLAlchemy engine for connection
engine = create_engine('postgresql://postgres:0624@localhost:5432/Telco2')

# Set the number of threads for KMeans to avoid memory leak
os.environ["OMP_NUM_THREADS"] = "2"  # Set to 1 or 2 to reduce the chance of memory leaks


def fetch_data():
    """
    Fetch data from the database and prepare GeoDataFrame.
    """
    # Define SQL queries
    cid_query = "SELECT cid, mkt_id, fip, cid_geom FROM cid_kmeans_gen;"
    eid_query = "SELECT eid, mkt_id FROM eid_employees;"

    # Fetch data from the database
    cid_df = pd.read_sql(cid_query, engine)
    eid_df = pd.read_sql(eid_query, engine)

    # Convert cid_geom to geometry
    cid_df['geometry'] = cid_df['cid_geom'].apply(wkt_loads)
    cid_gdf = gpd.GeoDataFrame(cid_df, geometry='geometry')

    return cid_gdf, eid_df  # Return GeoDataFrame and eid DataFrame


def apply_kmeans_per_market(cid_gdf, eid_df):
    """
    Apply DBSCAN clustering to each market in the GeoDataFrame to ensure contiguous clusters
    based on CID density.
    """
    cid_gdf['cluster'] = None  # Initialize column for cluster assignment

    # Iterate through each market
    for market_id in cid_gdf['mkt_id'].unique():
        # Filter CIDs and EIDs for the market
        market_cid_gdf = cid_gdf[cid_gdf['mkt_id'] == market_id].copy()
        market_eid_df = eid_df[eid_df['mkt_id'] == market_id]

        num_cids = len(market_cid_gdf)
        num_eids = len(market_eid_df)
        
        if num_eids == 0:
            print(f"Skipping market {market_id}: no EIDs available.")
            continue

        # Apply DBSCAN for spatial clustering based on CID locations
        coordinates = [
            (geom.x, geom.y) for geom in market_cid_gdf['geometry'] if geom.geom_type == 'Point'
        ]
        if len(coordinates) == 0:
            print(f"Skipping market {market_id}: no valid point geometries.")
            continue

        # Apply DBSCAN clustering with a spatial distance threshold (epsilon) to ensure geographical proximity
        dbscan = DBSCAN(eps=0.05, min_samples=2)  # Adjust eps based on the density of CIDs
        clusters = dbscan.fit_predict(np.array(coordinates))
        market_cid_gdf['cluster'] = clusters

        # Assign the clusters back to the original GeoDataFrame
        cid_gdf.loc[market_cid_gdf.index, 'cluster'] = market_cid_gdf['cluster']
    
    return cid_gdf


def assign_eids_to_clusters(cid_gdf, eid_df):
    """
    Assign EIDs to CID clusters proportionally based on CID density.
    The distribution is adjusted so that each EID gets an approximately equal number of CIDs.
    """
    assignments = []
    
    for market_id in cid_gdf['mkt_id'].unique():
        market_cid_gdf = cid_gdf[cid_gdf['mkt_id'] == market_id].copy()
        market_eid_df = eid_df[eid_df['mkt_id'] == market_id]
        
        num_cids = len(market_cid_gdf)
        num_eids = len(market_eid_df)
        
        if num_eids == 0 or num_cids == 0:
            print(f"Skipping market {market_id}: insufficient data.")
            continue

        # Determine how many CIDs each EID should be assigned
        cids_per_eid = num_cids // num_eids
        remainder = num_cids % num_eids  # Remainder for balancing the assignment

        # Sort CIDs by their geographic location to keep them relatively contiguous
        market_cid_gdf = market_cid_gdf.sort_values(by=['geometry'])

        # Assign CIDs to EIDs, distributing evenly
        cid_assignments = {}
        current_eid_idx = 0
        for i, row in market_cid_gdf.iterrows():
            # Assign the current CID to the current EID
            assigned_eid = market_eid_df.iloc[current_eid_idx]['eid']
            
            # Track how many CIDs have been assigned to the current EID
            if assigned_eid not in cid_assignments:
                cid_assignments[assigned_eid] = 0
            
            # Increment the count of CIDs assigned to the current EID
            cid_assignments[assigned_eid] += 1
            
            # If the current EID has been assigned enough CIDs, move to the next EID
            if cid_assignments[assigned_eid] >= cids_per_eid + (1 if current_eid_idx < remainder else 0):
                current_eid_idx += 1

            # Record the assignment
            assignments.append({'cid': row['cid'], 'eid': assigned_eid})

    return pd.DataFrame(assignments)


def insert_assignments(assignments_df):
    """
    Inserts or updates assignments into the cid_eid table.
    """
    # Convert DataFrame to a list of dictionaries for SQLAlchemy
    data = assignments_df.to_dict(orient='records')

    # Define the SQL query with named placeholders
    insert_query = """
        INSERT INTO cid_eid (cid, eid)
        VALUES (:cid, :eid)
        ON CONFLICT (cid) DO UPDATE SET eid = EXCLUDED.eid;
    """
    try:
        # Connect to the database
        with engine.connect() as conn:
            # Execute the query
            conn.execute(text(insert_query), data)
            # Commit the transaction
            conn.commit()
        print("Data successfully inserted/updated into 'cid_eid'.")
    except Exception as e:
        print(f"An error occurred during insertion: {e}")


# Main execution
if __name__ == "__main__":
    # Fetch data and prepare GeoDataFrame
    cid_gdf, eid_df = fetch_data()

    # Apply K-Means clustering
    cid_gdf = apply_kmeans_per_market(cid_gdf, eid_df)

    # Assign EIDs to clusters
    assignments_df = assign_eids_to_clusters(cid_gdf, eid_df)

    # Insert assignments into the database
    insert_assignments(assignments_df)
